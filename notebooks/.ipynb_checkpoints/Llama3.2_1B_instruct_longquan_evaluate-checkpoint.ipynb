{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1470d198-d235-4dfc-b81c-e17f6a9bd509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current GPU: Tesla P40\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "# Check if a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the current device index (default is 0 if no other device is specified)\n",
    "    current_device = torch.cuda.current_device()\n",
    "    \n",
    "    # Get the name of the GPU at this device index\n",
    "    gpu_name = torch.cuda.get_device_name(current_device)\n",
    "    print(f\"Current GPU: {gpu_name}\")\n",
    "else:\n",
    "    print(\"No GPU available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d374f4dd-8eb1-40eb-b1f2-4d6a2d56d161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !huggingface-cli download dataset longquan/llm-japanese-dataset-split_10\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Make sure to provide the correct `repo_id`\n",
    "dataset = load_dataset(\"longquan/llm-japanese-dataset-split_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23c7fa23-354e-4cd0-b05b-af6397020a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Splits: dict_keys(['train'])\n",
      "First Rows of Train Split: {'instruction': '次の日本語には間違っている部分があります。その部分を直して、正しい日本語の文を出力してください。', 'input': 'フライデースペシャル』（ニッポン放送）内で、１４：４０頃から放送されていた生放送コーナー「森野熊八\\u3000体いきいき楽しい食卓」が２０１４年１０月にて終了となり、後コーナーとし２０１４年１１月より開始された事前録音フロート番組。', 'output': 'フライデースペシャル』（ニッポン放送）内で、１４：４０頃から放送されていた生放送コーナー「森野熊八\\u3000体いきいき楽しい食卓」が２０１４年１０月にて終了となり、後コーナーとして２０１４年１１月より開始された事前録音フロート番組。'}\n"
     ]
    }
   ],
   "source": [
    "# Load dataset from local cache\n",
    "dataset = load_dataset(\"longquan/llm-japanese-dataset-split_10\", cache_dir=\"~/.cache/huggingface/datasets\")\n",
    "\n",
    "# View available dataset splits\n",
    "print(\"Available Splits:\", dataset.keys())\n",
    "\n",
    "# Load specific split (e.g., 'train') and inspect the first few rows\n",
    "train_data = dataset[\"train\"]\n",
    "print(\"First Rows of Train Split:\", train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e98344a1-ef7e-40be-8c65-a175c52290af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7007a10e-5ad6-462c-9727-a3c9f707f0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0578891d-50e6-4eb7-9b3f-e36ae8fd299c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference:  鉄板（てっぱん）とは、板状に伸ばした鉄鋼材料である。板金の一種。鋼板とも。 \n",
      "\n",
      "Model:  鉄板とは、鉄や金属の板に熱や電気を加え、熱や電気を吸収して熱や電気を生成する、熱や電気を生成する金属材料です。\n"
     ]
    }
   ],
   "source": [
    "random_sample = train_data[random.choice(range(train_data.num_rows))]\n",
    "\n",
    "reference = random_sample['output']\n",
    "print(\"Reference: \",reference,\"\\n\")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": random_sample[\"instruction\"]},\n",
    "    {\"role\": \"user\", \"content\": random_sample[\"input\"]}\n",
    "]\n",
    "outputs = pipe(\n",
    "    messages,\n",
    "    max_new_tokens=128,\n",
    ")\n",
    "candidate = outputs[0][\"generated_text\"][-1]['content']\n",
    "print(\"Model: \", candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f4560be-34fe-42f1-9eaa-a3d2a38538b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "from nltk import ngrams\n",
    "from collections import Counter\n",
    "from transformers import AutoTokenizer\n",
    "from bert_score import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63da31ee-34f0-4300-8adb-f0f73c1377ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def brevity_penalty(candidate, reference):\n",
    "    \"\"\"\n",
    "    Calculates the brevity penalty given the candidate and reference sentences.\n",
    "    \"\"\"\n",
    "    reference_length = len(reference)\n",
    "    candidate_length = len(candidate)\n",
    "\n",
    "    if reference_length < candidate_length:\n",
    "        BP = 1\n",
    "    else:\n",
    "        penalty = 1 - (reference_length / candidate_length)\n",
    "        BP = np.exp(penalty)\n",
    "\n",
    "    return BP\n",
    "\n",
    "\n",
    "def average_clipped_precision(candidate:str, reference:str,n:int):\n",
    "    \"\"\"\n",
    "    Calculates the precision given the candidate and reference sentences.\n",
    "    \"\"\"\n",
    "\n",
    "    clipped_precision_score = []\n",
    "    \n",
    "    # Loop through values 1, 2, 3, 4. This is the length of n-grams\n",
    "    for n_gram_length in range(1, n):\n",
    "        reference_n_gram_counts = Counter(ngrams(reference, n_gram_length))        \n",
    "        candidate_n_gram_counts = Counter(ngrams(candidate, n_gram_length))\n",
    "\n",
    "        total_candidate_ngrams = sum(candidate_n_gram_counts.values())       \n",
    "        \n",
    "        for ngram in candidate_n_gram_counts: \n",
    "            # check if it is in the reference n-gram\n",
    "            if ngram in reference_n_gram_counts:\n",
    "                # if the count of the candidate n-gram is bigger than the corresponding\n",
    "                # count in the reference n-gram, then set the count of the candidate n-gram \n",
    "                # to be equal to the reference n-gram\n",
    "                \n",
    "                if candidate_n_gram_counts[ngram] > reference_n_gram_counts[ngram]: \n",
    "                    candidate_n_gram_counts[ngram] = reference_n_gram_counts[ngram] # t\n",
    "                                                   \n",
    "            else:\n",
    "                candidate_n_gram_counts[ngram] = 0 # else set the candidate n-gram equal to zero\n",
    "\n",
    "        clipped_candidate_ngrams = sum(candidate_n_gram_counts.values())\n",
    "        \n",
    "        clipped_precision_score.append(clipped_candidate_ngrams / total_candidate_ngrams)\n",
    "    \n",
    "    # Calculate the geometric average: take the mean of elemntwise log, then exponentiate\n",
    "    # This is equivalent to taking the n-th root of the product as shown in equation (1) above\n",
    "    s = np.exp(np.mean(np.log(clipped_precision_score)))\n",
    "    \n",
    "    return s\n",
    "\n",
    "def calculate_bleu_score(reference:str,candidate:str, n:int):\n",
    "    assert n >=2, \"n must >= 2\"\n",
    "    BP = brevity_penalty(candidate, reference)    \n",
    "    geometric_average_precision = average_clipped_precision(candidate, reference, n)    \n",
    "    return BP * geometric_average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55d30c67-913a-40dd-83e1-81ce2d8282cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rouge(reference, generated, n=1, model_id = \"CohereForAI/aya-23-8B\"):\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    \n",
    "    # Tokenize the input strings into words\n",
    "    reference_tokens = tokenizer.tokenize(reference) #reference.split()\n",
    "    generated_tokens = tokenizer.tokenize(generated) #generated.split()\n",
    "    \n",
    "    # Generate n-grams\n",
    "    reference_ngrams = list(ngrams(reference_tokens, n))\n",
    "    generated_ngrams = list(ngrams(generated_tokens, n))\n",
    "    \n",
    "    # Count n-grams\n",
    "    reference_count = Counter(reference_ngrams)\n",
    "    generated_count = Counter(generated_ngrams)\n",
    "\n",
    "    # Calculate matched n-grams\n",
    "    matched_ngrams = reference_count & generated_count\n",
    "    \n",
    "    # Precision\n",
    "    precision = (sum(matched_ngrams.values()) / len(generated_ngrams)) if generated_ngrams else 0.0\n",
    "    \n",
    "    # Recall\n",
    "    recall = (sum(matched_ngrams.values()) / len(reference_ngrams)) if reference_ngrams else 0.0\n",
    "    \n",
    "    # F1 Score\n",
    "    if precision + recall > 0:\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    else:\n",
    "        f1_score = 0.0\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score\n",
    "    }\n",
    "\n",
    "def lcs_length(x, y):\n",
    "    \"\"\"Calculate the length of the longest common subsequence (LCS)\"\"\"\n",
    "    m, n = len(x), len(y)\n",
    "    # Create a 2D array to store lengths of longest common subsequence.\n",
    "    lcs_table = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "\n",
    "    # Fill the lcs_table\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if x[i - 1] == y[j - 1]:\n",
    "                lcs_table[i][j] = lcs_table[i - 1][j - 1] + 1\n",
    "            else:\n",
    "                lcs_table[i][j] = max(lcs_table[i - 1][j], lcs_table[i][j - 1])\n",
    "\n",
    "    return lcs_table[m][n]\n",
    "\n",
    "def calculate_rouge_l(reference, generated, model_id = \"CohereForAI/aya-23-8B\"):\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    \n",
    "    # Tokenize the input strings into words\n",
    "    reference_tokens = tokenizer.tokenize(reference) #reference.split()\n",
    "    generated_tokens = tokenizer.tokenize(generated) #generated.split()\n",
    "\n",
    "    # Calculate the length of the longest common subsequence\n",
    "    lcs_len = lcs_length(reference_tokens, generated_tokens)\n",
    "\n",
    "    # Precision\n",
    "    precision = lcs_len / len(generated_tokens) if generated_tokens else 0.0\n",
    "\n",
    "    # Recall\n",
    "    recall = lcs_len / len(reference_tokens) if reference_tokens else 0.0\n",
    "\n",
    "    # F1 Score\n",
    "    if precision + recall > 0:\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    else:\n",
    "        f1_score = 0.0\n",
    "\n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c92fb95b-2704-4ad6-bd88-a6a169f80292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-2: 0.3090909090909091\n",
      "BLEU-4: 0.10902663699559982\n"
     ]
    }
   ],
   "source": [
    "print(\"BLEU-2:\", bleu_score(reference, candidate,2))\n",
    "print(\"BLEU-4:\", bleu_score(reference, candidate,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd73d33d-22d5-4178-872d-7f9c4171ab6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-2: {'precision': 0.05263157894736842, 'recall': 0.07407407407407407, 'f1_score': 0.06153846153846154}\n",
      "ROUGE-3: {'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"ROUGE-2:\", calculate_rouge(reference, candidate, n=2))\n",
    "print(\"ROUGE-3:\", calculate_rouge(reference, candidate, n=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a641a609-b983-4730-a267-58b2efb29ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-L: {'precision': 0.20512820512820512, 'recall': 0.2857142857142857, 'f1_score': 0.23880597014925373}\n"
     ]
    }
   ],
   "source": [
    "# Calculate ROUGE-L\n",
    "rouge_l = calculate_rouge_l(reference, candidate)\n",
    "print(\"ROUGE-L:\", rouge_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07676891-b13a-4435-ab48-b635dffb743c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loc/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore: Precision=0.6821, Recall=0.7144, F1=0.6979\n"
     ]
    }
   ],
   "source": [
    "P, R, F1 = score([candidate], [reference], lang=\"ja\")  # Set language to Japanese\n",
    "print(f\"BERTScore: Precision={P.mean():.4f}, Recall={R.mean():.4f}, F1={F1.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040c5613-4ece-43fa-91bf-08f7a9e5dac0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
