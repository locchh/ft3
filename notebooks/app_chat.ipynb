{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def generate(input_text, slider_value):\n",
    "    # Simple example response\n",
    "    return f\"Input: {input_text}\\nMax new tokens: {slider_value}\"\n",
    "\n",
    "# Create the interface\n",
    "demo = gr.Interface(\n",
    "    fn=generate,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Prompt\"), \n",
    "        gr.Slider(label=\"Max new tokens\", value=20, maximum=1024, minimum=1)\n",
    "    ],\n",
    "    outputs=gr.Textbox(label=\"Completion\")\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "demo.launch(share=True, server_port=8080)  # Changed port to 8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "\n",
    "# Set up environment for GPU usage (Optional if using `device_map=\"auto\"`)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "def create_generation_pipeline(model_id=\"meta-llama/Llama-3.2-1B-Instruct\"):\n",
    "    return pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model_id,\n",
    "        device_map=\"auto\",  # Automatically assigns devices\n",
    "    )\n",
    "\n",
    "# Handle command-line arguments with a default model\n",
    "model_id = sys.argv[1] if len(sys.argv) > 1 else \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "pipe = create_generation_pipeline(model_id=model_id)\n",
    "\n",
    "def generate(input_text, slider_value):\n",
    "    # Use the pipeline to generate text\n",
    "    results = pipe(input_text, max_new_tokens=slider_value)\n",
    "    output_text = results[0][\"generated_text\"]  # Extract the text from the result\n",
    "    return f\"Input: {input_text}\\nOutput: {output_text}\"\n",
    "\n",
    "# Create the Gradio interface\n",
    "demo = gr.Interface(\n",
    "    fn=generate,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Prompt\"), \n",
    "        gr.Slider(label=\"Max new tokens\", value=20, maximum=1024, minimum=1)\n",
    "    ],\n",
    "    outputs=gr.Textbox(label=\"Completion\")\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "demo.launch(share=True, server_port=8080)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
