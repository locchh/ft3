{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1350b10-dccb-40e2-8aed-23a8466fd59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current GPU: Tesla P40\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import random\n",
    "\n",
    "import torch\n",
    "# Check if a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the current device index (default is 0 if no other device is specified)\n",
    "    current_device = torch.cuda.current_device()\n",
    "    \n",
    "    # Get the name of the GPU at this device index\n",
    "    gpu_name = torch.cuda.get_device_name(current_device)\n",
    "    print(f\"Current GPU: {gpu_name}\")\n",
    "else:\n",
    "    print(\"No GPU available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d969eafa-e939-4829-b7e5-987cc055dd6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f762bcbf-1798-4134-b739-15b63243739a",
   "metadata": {},
   "source": [
    "### aixsatoshi/cosmopedia-japanese-100k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1889baab-20f5-42b8-b3e2-c70b3ec148ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['format', 'japanese', 'english', 'audience', 'seed_data'],\n",
       "        num_rows: 99866\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "repo_id = \"aixsatoshi/cosmopedia-japanese-100k\"\n",
    "\n",
    "dataset = load_dataset(repo_id)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ce9c041-4085-4127-b319-f0ba58e1e758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Splits: dict_keys(['train'])\n",
      "First Rows of Train Split: {'format': 'blogpost', 'japanese': '自動車事故に巻き込まれた場合、特に商業トラックが絡む事故の場合、保険会社からの和解案を受け取ることが、しばしば頭に浮かびます。医療費、失われた賃金、財産の損害はすぐに積み重なり、あなたは経済的に苦境に立たされることになるからです。しかし、和解案の提示時期は、いくつかの要因によって大きく異なることがあります。このトピックのより深い洞察を得るために、さらに掘り下げてみましょう。\\n\\nまず第一に、和解交渉を行う前に、責任の所在を確立することが非常に重要です。医療記録、写真、目撃者の陳述書、その他の関連資料などの証拠を収集することで、あなたのケースの強固な基盤を築くことができます。経験豊富なオースティンのトラック事故弁護士は、このプロセスをガイドし、必要な証拠を効果的に収集・提示することができます。\\n\\n和解案の提示時期に大きな影響を与える要因の 1 つは、事件の複雑さです。複数の当事者が関与している場合、責任の所在を確定することがより複雑になり、和解交渉が遅れる可能性があります。また、重傷を負った事件では、医療評価や治療計画が必要になることが多く、これを正確にまとめて提示するには時間がかかります。\\n\\n和解案の提示時期に影響を与えるもう 1 つの重要な要素は、交渉当事者間のコミュニケーションです。つまり、あなたの代理人と保険調整者とのコミュニケーションです。一部の調整者は迅速に請求を解決するために懸命に働くかもしれませんが、他の調整者は和解金を低めに提示するために遅延戦術を使用したり、請求者を疲れさせようとするかもしれません。忍耐と粘り強さがここでは重要です。和解交渉を急ぐと、本来受け取るべき金額よりも低い和解金を受け取ることになる可能性があります。\\n\\nさらに、オースティンのトラック事故後に和解案を受け取るまでの時間は、それぞれのケースがユニークであるため、標準的なタイムラインはありません。一部の請求は数か月以内に解決する可能性がありますが、他の請求は予期せぬ事態や紛争により、1 年以上かかる可能性があります。和解交渉の状況を把握し、今後の見通しを理解するために、弁護士と常に連絡を取り合うことが重要です。\\n\\n最後に、交渉が緊張したり長引いたりした場合には、仲裁を検討することをお勧めします。仲裁人は、対立する当事者間の話し合いを促進し、妥協点を見つけて迅速な解決を目指す中立的な第三者です。仲裁人を介入させることで、双方が妥協し、より迅速かつ公正な結果を得ることができます。\\n\\n結論として、オースティンのトラック事故後の和解案提示までの時間は、さまざまな要因によって影響を受けます。証拠を徹底的に収集し、交渉を忍耐強く行い、代替的な紛争解決方法を検討することで、和解交渉のプロセスを合理化することができます。覚えておいてください。経験豊富なトラック事故弁護士と緊密に連携することで、あなたが受け取るべき和解金を確保することができ、たとえそれには少し待つことが必要であっても、より有利な結果を得ることができます。', 'english': \"When you've been involved in an auto accident, particularly one involving a commercial truck, receiving a settlement offer from the insurance company is often top of mind. After all, medical bills, lost wages, and property damage can quickly add up, leaving you financially strained. However, the timing of a settlement offer can vary greatly depending on several factors. Let's delve deeper into the nuances of this topic.\\n\\nFirst and foremost, before any settlement negotiation can occur, it's crucial to establish liability. Gathering evidence such as medical records, photographs, witness statements, and other relevant documentation helps build a solid foundation for your case. An experienced Austin truck accident attorney can guide you through this process and ensure that all necessary evidence is gathered and presented effectively. \\n\\nOne factor that can significantly impact the timeline of a settlement offer is the complexity of the case itself. For instance, if multiple parties are involved, determining responsibility becomes more intricate, potentially delaying the settlement process. Additionally, cases involving severe injuries usually require extensive medical evaluations and treatment plans, which takes time to compile and present accurately.\\n\\nAnother critical aspect influencing the speed of a settlement offer is communication between the two negotiating parties – i.e., your legal representative and the insurance adjuster. While some adjusters work diligently to resolve claims swiftly, others might employ stall tactics designed to lowball offers or wear down claimants. Patience and perseverance are essential here; attempting to rush the process could result in a lower payout than what you rightfully deserve.\\n\\nFurthermore, keep in mind that each case is unique, meaning there's no standard timeline for receiving a settlement offer following a truck accident. Some claims may reach resolution within months, while others might drag on for over a year due to unforeseen complications or disputes. It's vital to stay informed throughout the process, maintaining open lines of communication with your attorney to understand where things stand and what to expect moving forward.\\n\\nLastly, consider mediation as a viable option if negotiations become tense or protracted. Mediators act as impartial third parties who facilitate discussions between opposing counsel, aiming to find middle ground and expedite resolutions. By bringing in a mediator, both sides agree to compromise, often leading to faster (and fairer) outcomes.\\n\\nIn conclusion, various elements contribute to the length of time it takes for a settlement offer after an Austin truck accident. Building a strong case through thorough evidence collection, exercising patience during negotiations, and considering alternative dispute resolution methods can help streamline the process. Remember, staying informed and working closely with an experienced truck accident lawyer increases your chances of securing a favorable outcome, even if it requires a bit of waiting.\", 'audience': 'general', 'seed_data': 'web_samples_v2'}\n"
     ]
    }
   ],
   "source": [
    "# View available dataset splits\n",
    "print(\"Available Splits:\", dataset.keys())\n",
    "\n",
    "# Load specific split (e.g., 'train') and inspect the first few rows\n",
    "train_data = dataset[\"train\"]\n",
    "sample = train_data[0]\n",
    "print(\"First Rows of Train Split:\", sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e16e9531-f596-41ec-a4e9-d7de947ff9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': '**トラック自動車事故で settlement を受け取る際の考慮事項**\\n\\n自動車事故で事故の責任を調べることが大切です。医療費、失業、建物の損傷が急激になる可能性があるため、すぐに settlement を受け取ることは難しいことが多いです。ただし、 settlement の時期はさまざまな要因によって影響を受けることがあります。\\n\\n** settlement の時期を決定する上で重要な要素**\\n\\nまずは、医療費、失業、建物の損傷の費用を積極的に集めることです。医療費、失業、建物の損傷の費用を積極的に集めることで、 settlement の時期を早く決定できます。 settlement の時期を決定する上で重要な要素は、 settlement の時期が遅くなる場合の複雑さです。複雑な場合では、複数の人々が関与している場合、責任の分配が複雑になる可能性があるためです。\\n\\nまた、 settlement の時期を決定する上で重要な要素は、 settlement の時期が遅くなる場合の複雑さです。複雑な場合では、 settlement の時期が遅くなる場合、複数の人々が関与している場合、責任の分配が複雑になる可能性があるためです。\\n\\n** settlement の時期を早く決定するための方法**\\n\\n settlement の時期を早く決定するための方法には、以下の 2 つの方法があります。\\n\\n1.  ** settlement の時期を早く決定するために、積極的に settlement の時期を調べることです。** settlement の時期を早く決定するために、積極的に settlement の時期を調べることができます。 settlement の時期を早く決定する上で重要な要素は、 settlement の時期を早く決定することです。\\n2.  ** settlement の時期を早く決定するために、積極的に settlement の時期を調べることができます。** settlement の時期を早く決定するために、積極的に settlement の時期を調べることができます。 settlement の時期を早く決定する上で重要な要素は、 settlement の時期を早く決定することです。\\n\\n**'}\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a translator, your job is translate English to Japanese\"},\n",
    "    {\"role\": \"user\", \"content\" : \"Translate the given content to Japanese\"},\n",
    "    {\"role\": \"user\", \"content\" : sample['english']},\n",
    "     ]\n",
    "\n",
    "outputs = pipe(\n",
    "    messages,\n",
    "    max_new_tokens=512,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b5e9d0-5b62-4a33-8957-6383814b4f76",
   "metadata": {},
   "source": [
    "### shi3z/Japanese_wikipedia_conversation_100K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23980b64-2bb5-42b9-b8df-45183abfda02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['conversations'],\n",
       "        num_rows: 110322\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "repo_id = \"shi3z/Japanese_wikipedia_conversation_100K\"\n",
    "\n",
    "dataset = load_dataset(repo_id)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7b573fa-1814-4e4f-8ba4-8b16a4ab4828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Splits: dict_keys(['train'])\n",
      "First Rows of Train Split: {'conversations': [{'from': 'human', 'value': '宮川宗徳はどのような職業の経歴を持っていましたか？'}, {'from': 'gpt', 'value': '宮川宗徳は内務省、文部省、東京市の官吏として働いていました。彼は文書課長や保健局長などの役職を歴任しました。また、東京市会議員にも当選しました。'}, {'from': 'human', 'value': '宮川宗徳はなぜ公職追放を受けたのですか？'}, {'from': 'gpt', 'value': '宮川宗徳は戦後に公職追放を受けました。これは戦前の彼の関与した団体の活動が問題視されたためです。しかし、宮川は神社本庁事務総長を辞任せず、通達から三ヶ月後に組織化が完了したとして辞任しました。'}, {'from': 'human', 'value': '宮川宗徳はどのような貢献をしましたか？'}, {'from': 'gpt', 'value': '宮川宗徳は神社本庁設立に貢献し、初代事務総長として神社本庁を組織化しました。また、神宮奉斎会の常務理事や理事長も務めました。伊勢神宮式年遷宮奉賛会の発足にも関与しました。'}, {'from': 'human', 'value': '宮川宗徳の死去はいつですか？'}, {'from': 'gpt', 'value': '宮川宗徳は1963年1月18日に亡くなりました。'}]}\n"
     ]
    }
   ],
   "source": [
    "# View available dataset splits\n",
    "print(\"Available Splits:\", dataset.keys())\n",
    "\n",
    "# Load specific split (e.g., 'train') and inspect the first few rows\n",
    "train_data = dataset[\"train\"]\n",
    "\n",
    "sample = train_data[0]\n",
    "print(\"First Rows of Train Split:\", sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d54317ec-43aa-439a-abb8-3a58d2bbd859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'from': 'human', 'value': '宮川宗徳はどのような職業の経歴を持っていましたか？'},\n",
       " {'from': 'gpt',\n",
       "  'value': '宮川宗徳は内務省、文部省、東京市の官吏として働いていました。彼は文書課長や保健局長などの役職を歴任しました。また、東京市会議員にも当選しました。'},\n",
       " {'from': 'human', 'value': '宮川宗徳はなぜ公職追放を受けたのですか？'},\n",
       " {'from': 'gpt',\n",
       "  'value': '宮川宗徳は戦後に公職追放を受けました。これは戦前の彼の関与した団体の活動が問題視されたためです。しかし、宮川は神社本庁事務総長を辞任せず、通達から三ヶ月後に組織化が完了したとして辞任しました。'},\n",
       " {'from': 'human', 'value': '宮川宗徳はどのような貢献をしましたか？'},\n",
       " {'from': 'gpt',\n",
       "  'value': '宮川宗徳は神社本庁設立に貢献し、初代事務総長として神社本庁を組織化しました。また、神宮奉斎会の常務理事や理事長も務めました。伊勢神宮式年遷宮奉賛会の発足にも関与しました。'},\n",
       " {'from': 'human', 'value': '宮川宗徳の死去はいつですか？'},\n",
       " {'from': 'gpt', 'value': '宮川宗徳は1963年1月18日に亡くなりました。'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['conversations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae826b79-7649-4966-acaf-32e7a89310da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': '宮川宗徳はどのような職業の経歴を持っていましたか？'},\n",
       " {'role': 'assistant',\n",
       "  'content': '宮川宗徳は内務省、文部省、東京市の官吏として働いていました。彼は文書課長や保健局長などの役職を歴任しました。また、東京市会議員にも当選しました。'},\n",
       " {'role': 'user', 'content': '宮川宗徳はなぜ公職追放を受けたのですか？'},\n",
       " {'role': 'assistant',\n",
       "  'content': '宮川宗徳は戦後に公職追放を受けました。これは戦前の彼の関与した団体の活動が問題視されたためです。しかし、宮川は神社本庁事務総長を辞任せず、通達から三ヶ月後に組織化が完了したとして辞任しました。'},\n",
       " {'role': 'user', 'content': '宮川宗徳はどのような貢献をしましたか？'},\n",
       " {'role': 'assistant',\n",
       "  'content': '宮川宗徳は神社本庁設立に貢献し、初代事務総長として神社本庁を組織化しました。また、神宮奉斎会の常務理事や理事長も務めました。伊勢神宮式年遷宮奉賛会の発足にも関与しました。'},\n",
       " {'role': 'user', 'content': '宮川宗徳の死去はいつですか？'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = convert_to_llama_format(sample['conversations'])\n",
    "messages[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb825f8b-1889-4168-aaa9-467015d495b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': '宮川宗徳は1980年9月12日に死去しました。'}\n"
     ]
    }
   ],
   "source": [
    "outputs = pipe(\n",
    "    messages[:-1],\n",
    "    max_new_tokens=128,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9974aec-8a42-4b19-a591-3fb3dab73aff",
   "metadata": {},
   "source": [
    "### FreedomIntelligence/alpaca-gpt4-japanese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04d7b143-a7aa-4443-be4c-b041df3bcf52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['conversations', 'id'],\n",
       "        num_rows: 49969\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "repo_id = \"FreedomIntelligence/alpaca-gpt4-japanese\"\n",
    "\n",
    "dataset = load_dataset(repo_id)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a7567cf-a760-4663-9e87-39d4769b28af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Splits: dict_keys(['train'])\n",
      "First Rows of Train Split: {'conversations': [{'from': 'human', 'value': '再生可能運動のスローガンを提案してください。\\n'}, {'from': 'gpt', 'value': '1. 「減らそう、再利用しよう、リサイクルしよう：緑豊かな未来のために一緒に」\\n2. 「今日リサイクルして、明日をよくしよう」\\n3. 「ゴミを宝物に変えよう - リサイクル！」\\n4. 「生命の循環のためにリサイクル」\\n5. 「資源を節約し、より多くリサイクルしよう」'}], 'id': '23712'}\n"
     ]
    }
   ],
   "source": [
    "# View available dataset splits\n",
    "print(\"Available Splits:\", dataset.keys())\n",
    "\n",
    "# Load specific split (e.g., 'train') and inspect the first few rows\n",
    "train_data = dataset[\"train\"]\n",
    "sample = train_data[0]\n",
    "print(\"First Rows of Train Split:\", sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d152d445-7dee-404d-928d-68afa61fe829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': '再生可能運動のスローガンを提案してください。\\n'},\n",
       " {'role': 'assistant',\n",
       "  'content': '1. 「減らそう、再利用しよう、リサイクルしよう：緑豊かな未来のために一緒に」\\n2. 「今日リサイクルして、明日をよくしよう」\\n3. 「ゴミを宝物に変えよう - リサイクル！」\\n4. 「生命の循環のためにリサイクル」\\n5. 「資源を節約し、より多くリサイクルしよう」'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = convert_to_llama_format(sample['conversations'])\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6858d08-ebeb-4d3d-ad59-8b51c51a3c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': '再生可能エネルギーのスローガンは、次のとおりです。\\n\\n\"再生可能で持続可能な世界\"\\n\\nまたは、簡単に言うと \"再生可能で持続可能な地球\"\\n\\nこのスローガンは、再生可能エネルギーの重要性を強調し、人類の将来の世代を守ることができるような持続可能な世界を目指すものです。'}\n"
     ]
    }
   ],
   "source": [
    "outputs = pipe(\n",
    "    messages[:-1],\n",
    "    max_new_tokens=128,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e5d7be-129a-4a43-934f-bef7edd2c333",
   "metadata": {},
   "source": [
    "### FreedomIntelligence/evol-instruct-japanese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec3060c6-7f03-4e51-9601-42504bc76e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['conversations', 'id'],\n",
       "        num_rows: 59022\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "repo_id = \"FreedomIntelligence/evol-instruct-japanese\"\n",
    "\n",
    "dataset = load_dataset(repo_id)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cfab4ab-d7d5-4197-9f90-b94b714a22be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Splits: dict_keys(['train'])\n",
      "First Rows of Train Split: {'conversations': [{'from': 'human', 'value': '「名前」、「年齢」、そして「給料」という三列のデータフレームを作成するRのコードは何ですか？ 「名前」の列には、「John」、「Mary」、そして「Peter」という値を入れます。 「年齢」の列には25、30、35という値を入れます。そして、「給料」の列には50000、60000、70000という値を入れます。このデータフレームを作成するための [Rのコード] ソリューションを提供してください。\\n'}, {'from': 'gpt', 'value': '以下は、名前、年齢、そして給料という三列のデータフレームを作成するためのRコードです。\\n\\n```\\ndata <- data.frame(\\n  名前 = c(\"John\", \"Mary\", \"Peter\"),\\n  年齢 = c(25, 30, 35),\\n  給料 = c(50000, 60000, 70000)\\n)\\n```\\n\\nまず、`data.frame()`関数を使用して、`data`という名前の新しいデータフレームを作成します。`c()`関数を使用して、名前、年齢、そして給料の列の各値をベクトル形式で追加します。\\n\\n最終的に、`data`変数には、次のような三列のデータフレームが格納されます。\\n\\n```\\n#   名前 年齢   給料\\n# 1 John  25 50000\\n# 2 Mary  30 60000\\n# 3 Peter 35 70000\\n```\\n\\nこのデータフレームを表示するには、`data`を単に入力するだけで、Rコンソールに出力されます。'}], 'id': '36655'}\n"
     ]
    }
   ],
   "source": [
    "# View available dataset splits\n",
    "print(\"Available Splits:\", dataset.keys())\n",
    "\n",
    "# Load specific split (e.g., 'train') and inspect the first few rows\n",
    "train_data = dataset[\"train\"]\n",
    "sample = train_data[0]\n",
    "print(\"First Rows of Train Split:\", sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b82f2ad-5bbb-4928-bf29-ea81f7f74f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': '「名前」、「年齢」、そして「給料」という三列のデータフレームを作成するRのコードは何ですか？ 「名前」の列には、「John」、「Mary」、そして「Peter」という値を入れます。 「年齢」の列には25、30、35という値を入れます。そして、「給料」の列には50000、60000、70000という値を入れます。このデータフレームを作成するための [Rのコード] ソリューションを提供してください。\\n'},\n",
       " {'role': 'assistant',\n",
       "  'content': '以下は、名前、年齢、そして給料という三列のデータフレームを作成するためのRコードです。\\n\\n```\\ndata <- data.frame(\\n  名前 = c(\"John\", \"Mary\", \"Peter\"),\\n  年齢 = c(25, 30, 35),\\n  給料 = c(50000, 60000, 70000)\\n)\\n```\\n\\nまず、`data.frame()`関数を使用して、`data`という名前の新しいデータフレームを作成します。`c()`関数を使用して、名前、年齢、そして給料の列の各値をベクトル形式で追加します。\\n\\n最終的に、`data`変数には、次のような三列のデータフレームが格納されます。\\n\\n```\\n#   名前 年齢   給料\\n# 1 John  25 50000\\n# 2 Mary  30 60000\\n# 3 Peter 35 70000\\n```\\n\\nこのデータフレームを表示するには、`data`を単に入力するだけで、Rコンソールに出力されます。'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = convert_to_llama_format(sample['conversations'])\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b636498c-26e2-401e-b2c6-9b03f50eff2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': '以下は、Rのコードを使用して三列のデータフレームを作成するソリューションです。\\n\\n```r\\n# データフレームの作成\\ndata <- data.frame(\\n  Name = c(\"John\", \"Mary\", \"Peter\"),\\n  Age = c(25, 30, 35),\\n  Salary = c(50000, 60000, 70000)\\n)\\n\\n# データフレームを表示\\nprint(data)\\n\\n# または、データフレームの各列を表示\\nprint(paste(\"Name:\", data$Name))\\nprint(paste(\"Age:\", data'}\n"
     ]
    }
   ],
   "source": [
    "outputs = pipe(\n",
    "    messages[:-1],\n",
    "    max_new_tokens=128,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f070007e-3f72-4ef8-ba2f-af349c6a51d2",
   "metadata": {},
   "source": [
    "### longquan/llm-japanese-dataset-split_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "345732dd-2232-4920-a2e9-be220061f25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output'],\n",
       "        num_rows: 251655\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "repo_id = \"longquan/llm-japanese-dataset-split_10\"\n",
    "\n",
    "dataset = load_dataset(repo_id)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88c361df-2de1-473d-a58f-7a81c931a34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Splits: dict_keys(['train'])\n",
      "First Rows of Train Split: {'instruction': '次の日本語には間違っている部分があります。その部分を直して、正しい日本語の文を出力してください。', 'input': 'フライデースペシャル』（ニッポン放送）内で、１４：４０頃から放送されていた生放送コーナー「森野熊八\\u3000体いきいき楽しい食卓」が２０１４年１０月にて終了となり、後コーナーとし２０１４年１１月より開始された事前録音フロート番組。', 'output': 'フライデースペシャル』（ニッポン放送）内で、１４：４０頃から放送されていた生放送コーナー「森野熊八\\u3000体いきいき楽しい食卓」が２０１４年１０月にて終了となり、後コーナーとして２０１４年１１月より開始された事前録音フロート番組。'}\n"
     ]
    }
   ],
   "source": [
    "# View available dataset splits\n",
    "print(\"Available Splits:\", dataset.keys())\n",
    "\n",
    "# Load specific split (e.g., 'train') and inspect the first few rows\n",
    "train_data = dataset[\"train\"]\n",
    "sample = train_data[0]\n",
    "print(\"First Rows of Train Split:\", sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c12e6b88-b474-4f7c-858b-26a228b0a658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are helpful assistant'},\n",
       " {'role': 'user',\n",
       "  'content': '次の日本語には間違っている部分があります。その部分を直して、正しい日本語の文を出力してください。'},\n",
       " {'role': 'user',\n",
       "  'content': 'フライデースペシャル』（ニッポン放送）内で、１４：４０頃から放送されていた生放送コーナー「森野熊八\\u3000体いきいき楽しい食卓」が２０１４年１０月にて終了となり、後コーナーとし２０１４年１１月より開始された事前録音フロート番組。'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if sample[\"input\"]:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are helpful assistant\"},\n",
    "        {\"role\": \"user\", \"content\" : sample[\"instruction\"]},\n",
    "        {\"role\": \"user\", \"content\" : sample['input']},\n",
    "         ]\n",
    "else:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are helpful assistant\"},\n",
    "        {\"role\": \"user\", \"content\" : sample[\"instruction\"]},\n",
    "         ]\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48672c9c-3267-4b8c-a877-0eb5f6b921b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': 'フライデースペシャル（ニッポン放送）内で、１４：４０頃から放送されていた生放送コーナー「森野熊八\\u3000体いきいき楽しい食卓」は、２０１４年１０月に終了しました。後続コーナーに代わって、２０１４年１１月から開始された事前録音フロート番組が始まりました。'}\n"
     ]
    }
   ],
   "source": [
    "outputs = pipe(\n",
    "    messages,\n",
    "    max_new_tokens=128,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f02bb46-3cd0-42b0-a636-aada520b57cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
